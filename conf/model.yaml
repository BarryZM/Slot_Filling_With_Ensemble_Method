require_improvement: 15
batch_size: 32

lr: 0.0003
lr_decay: 0.05
l2: 0.00000001
momentum: 0
epoch: 1000
dropout: 0.5
random_embedding: True

char_emb_dim: 300
#word_emb_dim: 300

# model_num对应不同的模型结构
model_num: 1
model:
  0: {encoder_type: "cnn_lstm", char_hidden_dim: 50, word_hidden_dim: 200, kernel_size: 3, padding: 1, num_layers: 1, num_output: 256}
  1: {encoder_type: "bilstm_crf", hidden_dim: 200, num_layers: 1, batch_first: True, bidirectional: True, feature_emb_dim: 100,
      model_path: "saved_models/slot_filling/bilstm_crf/bilstm_crf"}
  2: {encoder_type: "attn_bilstm_crf", hidden_dim: 200, num_layers: 1, batch_first: True, bidirectional: True, feature_emb_dim: 300,
      model_path: "saved_models/slot_filling/attn_bilstm_crf/attn_bilstm_crf"}
  3: {encoder_type: "cnn_attn_lstm_crf", cnn_hidden_dim: 300, lstm_hidden_dim: 200, num_layers: 1, batch_first: True, bidirectional: True,
      word_emb_dim: 280, intent_emb_dim: 100, lexi_emb_dim: 20, model_path: "saved_models/slot_filling/cnn_attn_lstm_crf/cnn_attn_lstm_crf"}
  4: {encoder_type: "mul_bilstm_crf", hidden_dim: 200, num_layers: 1, batch_first: True, bidirectional: True, feature_emb_dim: 300,
      model_path: "saved_models/slot_filling/mul_bilstm_crf/mul_bilstm_crf"}